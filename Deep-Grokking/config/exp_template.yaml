#================================================================
# Experiment Configuration Template for Grokking
#================================================================
# Use placeholders like ${VAR_NAME} for parameters you intend
# to sweep or change frequently via command-line or scripts.

#--------------------------------
# Environment Settings
#--------------------------------
device: 'cuda'    # Device to use: 'cuda' or 'cpu'
seed: 42          # Random seed for reproducibility

#--------------------------------
# Data & Model Architecture
#--------------------------------
data_dir: './data'
input_dim: 784      # MNIST image flattened size (28*28)
output_dim: 10      # Number of classes (digits 0-9)
hidden_dim: 400     # Width of hidden layers
n_train: ${n_train} # Number of training samples (e.g., 2000, 5000)
depth: ${depth}     # Number of hidden layers (e.g., 4, 8)
alpha: ${alpha}     # Scale for weight initialization (e.g., 8.0)

#--------------------------------
# Training Hyperparameters
#--------------------------------
lr: 1.0e-3                    # Learning rate for the main model
weight_decay: ${weight_decay} # L2 regularization strength (e.g., 0.005)
batch_size: 128               # Batch size for training and evaluation
max_steps: 100000             # Total training steps

#--------------------------------
# Logging & Checkpointing
#--------------------------------
log_interval: 1              # Step interval for logging basic metrics (loss, acc)
save_dir: './checkpoints'       # Base directory to save model checkpoints

# --- Metrics to Log ---
# These flags control which metrics are logged at each `log_interval`.
log_train_loss: true
log_test_loss: true
log_train_acc: true
log_test_acc: true
log_weight_norm: true

#--------------------------------
# Probing Analysis Settings
#--------------------------------
# Probing is a more expensive analysis run less frequently.
probe_interval: 5000      # Step interval for running probing analysis
probe_steps: 1000         # Number of training steps for the linear probe
probe_lr: 1.0e-3          # Learning rate for the linear probe optimizer
probe_eps: 1.0e-5         # Epsilon for effective rank calculation

#--------------------------------
# Weights & Biases Settings (Optional)
#--------------------------------
use_wandb: true
project_name: 'grokking-experiments'
# Note: The run name is generated automatically by the training script based on parameters.